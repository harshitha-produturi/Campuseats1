{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitha-produturi/Campuseats1/blob/main/BDA_assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1.Build a classification model with spark with a dataset of your choice in python for big data analysis.\n"
      ],
      "metadata": {
        "id": "PF9IJbRmVxLY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aon2cCiYKD3p",
        "outputId": "6ac1aa68-33be-4de1-b799-2f2722658a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----+----------+\n",
            "|          features|label|prediction|\n",
            "+------------------+-----+----------+\n",
            "|[45.0,130.0,220.0]|    1|       1.0|\n",
            "|[33.0,112.0,185.0]|    0|       0.0|\n",
            "+------------------+-----+----------+\n",
            "\n",
            "Test AUC: 1.00\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"MedicalDiagnosisClassification\").getOrCreate()\n",
        "\n",
        "# Simulated patient data: (age, blood_pressure, cholesterol_level, label)\n",
        "data = [\n",
        "    (45, 130, 220, 1),\n",
        "    (50, 140, 230, 1),\n",
        "    (30, 120, 180, 0),\n",
        "    (60, 160, 250, 1),\n",
        "    (35, 110, 190, 0),\n",
        "    (40, 125, 200, 0),\n",
        "    (55, 145, 240, 1),\n",
        "    (38, 118, 195, 0),\n",
        "    (48, 135, 210, 1),\n",
        "    (33, 112, 185, 0)\n",
        "]\n",
        "\n",
        "# Define schema\n",
        "columns = [\"age\", \"blood_pressure\", \"cholesterol_level\", \"label\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Assemble features\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"age\", \"blood_pressure\", \"cholesterol_level\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df_prepared = assembler.transform(df).select(\"features\", \"label\")\n",
        "\n",
        "# Split the dataset\n",
        "train_data, test_data = df_prepared.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Decision Tree model\n",
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "model = dt.fit(train_data)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()\n",
        "\n",
        "# Evaluate model\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"Test AUC: {auc:.2f}\")\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Build a clustering model with spark with a data set of your choice"
      ],
      "metadata": {
        "id": "_KWRGjvbV6LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"TouristLocationClustering\").getOrCreate()\n",
        "\n",
        "# New dataset: (distance_to_city_center, popularity_score, number_of_reviews)\n",
        "data = [\n",
        "    (2.5, 8.0, 15.0),\n",
        "    (0.5, 9.5, 30.0),\n",
        "    (10.0, 3.0, 5.0),\n",
        "    (12.0, 2.5, 2.0),\n",
        "    (1.0, 9.0, 25.0),\n",
        "    (8.5, 4.0, 6.0),\n",
        "    (0.8, 8.7, 28.0)\n",
        "]\n",
        "\n",
        "columns = [\"distance_to_city_center\", \"popularity_score\", \"number_of_reviews\"]\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Feature assembler\n",
        "assembler = VectorAssembler(inputCols=columns, outputCol=\"features\")\n",
        "df_features = assembler.transform(df).select(\"features\")\n",
        "\n",
        "# KMeans clustering\n",
        "kmeans = KMeans(k=2, seed=1)\n",
        "model = kmeans.fit(df_features)\n",
        "predictions = model.transform(df_features)\n",
        "\n",
        "# Show clustering results\n",
        "predictions.show(truncate=False)\n",
        "\n",
        "print(\"Cluster Centers:\")\n",
        "for center in model.clusterCenters():\n",
        "    print(center)\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "OX8vE9xlK96Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a07b74f-b368-4b46-91d3-8b1c25230052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+\n",
            "|features      |prediction|\n",
            "+--------------+----------+\n",
            "|[2.5,8.0,15.0]|0         |\n",
            "|[0.5,9.5,30.0]|1         |\n",
            "|[10.0,3.0,5.0]|0         |\n",
            "|[12.0,2.5,2.0]|0         |\n",
            "|[1.0,9.0,25.0]|1         |\n",
            "|[8.5,4.0,6.0] |0         |\n",
            "|[0.8,8.7,28.0]|1         |\n",
            "+--------------+----------+\n",
            "\n",
            "Cluster Centers:\n",
            "[8.25  4.375 7.   ]\n",
            "[ 0.76666667  9.06666667 27.66666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Build a recommondation engine with spark with a dataset of your choice"
      ],
      "metadata": {
        "id": "ofGVU5sgWWh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"MusicRecommendation\").getOrCreate()\n",
        "\n",
        "# New dataset: user_id, song_id, rating\n",
        "data = [\n",
        "    (1, 301, 5.0),\n",
        "    (1, 302, 3.5),\n",
        "    (1, 303, 4.0),\n",
        "    (2, 301, 2.0),\n",
        "    (2, 304, 4.5),\n",
        "    (2, 305, 3.0),\n",
        "    (3, 302, 4.0),\n",
        "    (3, 303, 2.5),\n",
        "    (3, 306, 5.0),\n",
        "    (4, 304, 4.0),\n",
        "    (4, 305, 4.5),\n",
        "    (4, 306, 5.0),\n",
        "    (5, 301, 4.5),\n",
        "    (5, 303, 4.0),\n",
        "    (5, 305, 3.0),\n",
        "]\n",
        "\n",
        "columns = [\"user_id\", \"song_id\", \"rating\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Split data\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Build ALS model\n",
        "als = ALS(\n",
        "    userCol=\"user_id\",\n",
        "    itemCol=\"song_id\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",\n",
        "    nonnegative=True,\n",
        "    implicitPrefs=False,\n",
        "    rank=10,\n",
        "    maxIter=10,\n",
        "    regParam=0.1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model = als.fit(train_data)\n",
        "\n",
        "# Predict ratings\n",
        "predictions = model.transform(test_data)\n",
        "predictions.show()\n",
        "\n",
        "# Evaluate RMSE\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Test RMSE: {rmse:.2f}\")\n",
        "\n",
        "# Recommend top 3 songs for each user\n",
        "user_recs = model.recommendForAllUsers(3)\n",
        "user_recs.show(truncate=False)\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "608c2cwoU3Vy",
        "outputId": "d14e1270-966c-49a9-8294-97eb1e602901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+------+----------+\n",
            "|user_id|song_id|rating|prediction|\n",
            "+-------+-------+------+----------+\n",
            "|      3|    302|   4.0| 1.1997145|\n",
            "|      5|    301|   4.5| 1.2111512|\n",
            "+-------+-------+------+----------+\n",
            "\n",
            "Test RMSE: 3.05\n",
            "+-------+------------------------------------------------------+\n",
            "|user_id|recommendations                                       |\n",
            "+-------+------------------------------------------------------+\n",
            "|1      |[{301, 4.856713}, {302, 3.4991}, {304, 2.9036098}]    |\n",
            "|2      |[{304, 4.2876225}, {306, 3.2775788}, {305, 3.0627122}]|\n",
            "|3      |[{306, 4.945777}, {305, 4.221437}, {304, 3.9598732}]  |\n",
            "|4      |[{306, 5.0002613}, {305, 4.276373}, {304, 4.032666}]  |\n",
            "|5      |[{306, 3.4234986}, {305, 2.9560266}, {304, 2.9392178}]|\n",
            "+-------+------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}